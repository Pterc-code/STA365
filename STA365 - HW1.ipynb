{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d36e2a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importsall\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d3458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "theta_a = 0.5\n",
    "theta_b = 0.6\n",
    "theta_c = 0.8\n",
    "\n",
    "\n",
    "# Given that we don't know anything about the theta\n",
    "a_alpha = 1\n",
    "a_beta = 1\n",
    "\n",
    "b_alpha = 1\n",
    "b_beta = 1\n",
    "\n",
    "c_alpha = 1\n",
    "c_beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d0bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    a_outcome = stats.beta(a_alpha, a_beta).rvs()\n",
    "    b_outcome = stats.beta(b_alpha, b_beta).rvs()\n",
    "    c_outcome = stats.beta(c_alpha, c_beta).rvs()\n",
    "    \n",
    "    outcome = {a_outcome: 'a', b_outcome: 'b', c_outcome: 'c'}\n",
    "    result = max(outcome)\n",
    "    \n",
    "    \n",
    "    if outcome[result] == 'a':\n",
    "        # Update the posterior\n",
    "        x = stats.binom(n = 1, p = theta_a).rvs(size = 1)\n",
    "        a_alpha += x\n",
    "        a_beta += 1 - x\n",
    "    if outcome[result] == 'b':\n",
    "        # Update the posterior\n",
    "        x = stats.binom(n = 1, p = theta_b).rvs(size = 1)\n",
    "        b_alpha += x\n",
    "        b_beta += 1 - x\n",
    "    if outcome[result] == 'c':\n",
    "        # Update the posterior\n",
    "        x = stats.binom(n = 1, p = theta_c).rvs(size = 1)\n",
    "        c_alpha += x\n",
    "        c_beta += 1 - x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68d654",
   "metadata": {},
   "source": [
    "parameter_domain = np.linspace(0 ,1 ,1001)\n",
    "\n",
    "a_graph = stats.beta(a_alpha, a_beta).pdf(parameter_domain)\n",
    "b_graph = stats.beta(b_alpha, b_beta).pdf(parameter_domain)\n",
    "c_graph = stats.beta(c_alpha, c_beta).pdf(parameter_domain)\n",
    "\n",
    "plt.plot(parameter_domain, a_graph, label=\"a\")\n",
    "plt.plot(parameter_domain, b_graph, label=\"b\")\n",
    "plt.plot(parameter_domain, c_graph, label=\"c\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a6703",
   "metadata": {},
   "source": [
    "The data in this question are the trials of the sampling of the beta distribution outcome; notice that with each iteration we inch closer to the true probability. We follow the distribution given in class in order to update our parameters, that is, on success trials we update alpha by adding x and beta by adding 1 - x. \n",
    "\n",
    "In the first trial, since I have no prior data on what I believe which is the better choice, I assign a beta(1, 1) to all of the choices. In each iteration of the trail I choose the outcome that has the maximum probability of winning and update my posterior. In the end, this algorithm should output the best choice (c), which was the case as demonstrated by the graph. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
